---
title: "Modelos Autoregressivos de médias móveis (ARMA)"
title-slide-attributes:
  data-background-image: Marca_UEPB.png
  data-background-size: contain
  data-background-opacity: "0.15"
author: "Professor: Pedro M. Almeida-Junior"
institute: "Universidade Estadual da Paraíba"
format: 
  revealjs: 
    width: 1000
    margin: 0.1
    logo: Marca_UEPB.png
    theme: [default, hscroll.scss]
    transition: slide
    background-transition: fade
    smaller: true
    scrollable: true
knitr:
  opts_chunk:
    message: false
    warning: false
css: hscroll.scss
editor: 
  markdown: 
    wrap: 72
---

## <span style="font-size: 60px;"> Principais Abordagens em ST </span>

</br>

- Os modelos de suavização exponencial e ARMA são as duas abordagens mais utilizadas para a previsão de séries temporais. 


</br>


- Os modelos de suavização exponencial são baseados na descrição da [tendência]{.underline} e [sazonalidade]{.underline} dos dados 

</br>

- Os modelos ARMA visam descrever as [autocorrelações]{.underline} nos dados.


# Principais conceitos de ST

## <span style="font-size: 60px;"> Estacionariedade </span>

</br>

- Uma das suposições que podemos fazer em uma série temporal é a de que ela é **estacionária**. 


</br>

- Ao longo do tempo seus valores estão aleatoriamente próximos de uma média constante, refletindo de alguma forma um equilíbrio estável. 



## <span style="font-size: 60px;"> Exemplo de série estacionária </span>


```{r, echo=F}

x1 = rnorm(100, mean = 10, sd = 1)
ts.plot(x1, xlab = "Tempo", ylab = "Valores", main = "Exemplo de uma série estacionária" )#+abline(h = mean(x1), lty = "dashed", col = "red")
```


## <span style="font-size: 50px;"> Processos estocásticos estacionários </span>

**Definição:** Um processo estocástico $Z=\{Z(t), t \in \tau\}$\$ diz-se estritamente estacionário se todas as distribuições finito-dimensionais permanecem as mesmas sob translações no tempo, ou seja,

$$
F\left(z_1, \ldots, z_n ; t_1+\tau, \ldots, t_n+\tau\right)=F\left(z_1, \ldots, z_n ; t_1, \ldots, t_n\right)
$$

para quaisquer $t_1, \ldots, t_n, \tau$.

Isto significa, em particular, que todas as distribuições unidimensionais são invariantes sob translações do tempo, logo a média $\mu(t)$ e a variância $V(t)$ são constantes, isto é,

$$
\mu(t)=\mu, \quad V(t)=\sigma^2,
$$

para todo $t \in \tau$. Sem perda de generalidade, podemos supor que $\mu=0$; caso contrário, considere o processo $\{Z(t)-\mu\}$.


## <span style="font-size: 50px;"> Lidando com a não estacionariedade </span>


- Em várias situações práticas, vamos ter que lidar com **séries não estacionárias**. 

- É bastante comum, por exemplo, em séries econômicas e financeiras a presença de tendências de longos períodos ou curtos períodos (o que geralmente caracteriza uma mudança de nível). 

- Os modelos ARMA assumem como pressupostos que o processo é estacionário. 

- Assim, vamos ter que "tratar" a [não estacionariedade]{.underline} das séries através de transformações. 

- A transformação mais comum seria tomar diferenças sucessivas da série original, até obter uma série estacionária.

## <span style="font-size: 50px;">  Operador Diferença  </span>

O operador diferença ( $\Delta$ ) de primeira ordem pode ser definido como

$$
\Delta Z_t = Z_t - Z_{t-1}
$$

a segunda diferença é

$$
\Delta^2Z_t = \Delta[ \Delta Z_t ] = \Delta [ Z_t - Z_{t-1} ] 
$$

De modo geral, a n-ésima diferença de $Z_t$ é

$$
 \Delta^n Z_t = \Delta[ \Delta^{n-1} Z_t ]
$$

Na prática, é comum tomar uma ou duas diferenças para tornar a série temporal estacionária. 

## <span style="font-size: 50px;"> Exemplo simulado no R: </span>

```{r}
# Carregar pacotes necessários
library(ggplot2)
library(patchwork)

# Gerar dados
set.seed(1000)
x1 <- c()
for (i in 1:100) x1[i] <- rnorm(1, mean = 10 + (i / 2), sd = 1)
x2 <- diff(x1, 1)

# Criar data frames para os gráficos
df1 <- data.frame(Tempo = 1:100, Valores = x1)
df2 <- data.frame(Tempo = 2:100, Valores = x2)

# Gráfico da série original (não estacionária)
g1 <- ggplot(df1, aes(x = Tempo, y = Valores)) +
  geom_line(color = "steelblue") +
  labs(title = "Série não estacionária", x = "Tempo", y = "Valores") +
  theme_minimal()

# Gráfico da série diferenciada
g2 <- ggplot(df2, aes(x = Tempo, y = Valores)) +
  geom_line(color = "darkgreen") +
  labs(title = "Série com 1ª diferença", x = "Tempo", y = "Valores") +
  theme_minimal()

# Exibir lado a lado
g1 + g2
```



## <span style="font-size: 50px;"> Teste da Raíz unitária </span>

- Uma maneira de determinar mais objetivamente se a diferenciação é necessária é usar um *teste de raiz unitária* . 

- Estes são testes estatísticos de hipóteses de estacionariedade que são projetados para determinar se a diferenciação é necessária.

- Para verificar se uma série é estacionária, vamos usar o *teste de Kwiatkowski-Phillips-Schmidt-Shin (KPSS)* ( [Kwiatkowski et al., 1992](https://otexts.com/fpp3/stationarity.html#ref-KPSS92) ) . 

- Neste teste, a hipótese nula é que os dados são estacionários, e procuramos evidências de que a hipótese nula é falsa. Consequentemente, pequenos valores de *p-value* (por exemplo, menos de 0,05 ou 0,01) sugerem que a diferenciação é necessária. O teste pode ser calculado usando a função do R `unitroot_kpss().`

## <span style="font-size: 40px;"> Código R para rodar o teste da raiz unitaria no exemplo anterior </span>

```{r, echo =T, warning=FALSE, message=FALSE}
## Teste raiz unitaria para a serie com tendencia
feasts::unitroot_kpss( x1  )

## Teste raiz unitaria para a serie diferenciada
feasts::unitroot_kpss( x2  )



```

## <span style="font-size: 50px;"> Exemplo no R (Preço das ações do Google) </span>

Carregando os pacotes:

```{r, echo = T, warning=FALSE, message=FALSE}
library(dplyr)
library(forecast) 
library(fpp3)
library(tsibble)
```

Obtendo os dados

```{r, echo = T, warning=FALSE, message=FALSE}
google_2015 <- gafa_stock %>%
  filter(Symbol == "GOOG", year(Date) == 2015)

p1 = google_2015 %>% 
  autoplot(  ) + labs(subtitle = "Preços das ações do Google")

p2 = google_2015 %>% 
  mutate( Diff = difference(Close) )  %>%
  select( Date, Diff ) %>% 
  autoplot(   ) + labs(subtitle = "Diferenciação dos Preços das ações do Google")

```

Séries dos preços das ações do google no ano de 2015 e sua respectiva diferenciação.

```{r, echo = T, warning=FALSE, message=FALSE}
gridExtra::grid.arrange(p1, p2, ncol = 1)

```

Usando a função `unitroot_kpss` para testar se existe estacionariedade na serie

```{r, echo = T, warning=FALSE, message=FALSE}
google_2015 %>%
  features(Close, unitroot_kpss)

google_2015 %>%
   mutate( Diff = difference(Close) )  %>%
  features(Diff, unitroot_kpss)
```

Portanto, através do teste da raiz unitária, podemos concluir que a propriedade de estacionariedade da série é alcançada com apenas uma diferenciação.




## <span style="font-size: 50px;"> Autocorrelação </span>

Assim como a correlação mede a extensão de uma relação linear entre duas variáveis, a autocorrelação mede a relação linear entre os valores defasados de uma série temporal.

Existem vários coeficientes de autocorrelação, correspondentes a cada linha vertical no gráfico dos lags. Por exemplo, $r_1$ mede a relação entre $y_t \text{ e } y_{t-1}, r_2$ mede a relação entre $y_t \text{ e } y_{t-2}$, e assim por diante.

O valor de $k$ pode ser escrito como

$$
r_k=\frac{\sum_{t=k+1}^T\left(y_t-\bar{y}\right)\left(y_{t-k}-\bar{y}\right)}{\sum_{t=1}^T\left(y_t-\bar{y}\right)^2},
$$

Onde $T$ é o comprimento da série temporal. Os coeficientes de autocorrelação compõem a função de autocorrelação ou ACF.


## <span style="font-size: 50px;"> Impacto da tendência na ACF </span>

- Quando os dados apresentam um comportamento de tendência, as autocorrelações para pequenas defasagens tendem a ser grandes e positivas porque as observações próximas no tempo também estão próximas em valor. 


```{r}
# Carregar pacotes necessários
library(ggplot2)
library(patchwork)

# Gerar dados
set.seed(1000)
x1 <- c()
for (i in 1:100) x1[i] <- rnorm(1, mean = 10 + (i / 2), sd = 1)

# Criar data frames para os gráficos
df1 <- data.frame(Tempo = 1:100, Valores = x1)

# Gráfico da série original (não estacionária)
g1 <- ggplot(df1, aes(x = Tempo, y = Valores)) +
  geom_line(color = "steelblue") +
  labs(title = "Série não estacionária", x = "Tempo", y = "Valores") +
  theme_minimal()

# Gráficos de ACF com ggAcf
acf1 <- ggAcf(x1) + 
  labs(title = "ACF da série não estacionária") +
  theme_minimal()

# Exibir lado a lado
g1 + acf1
```


## <span style="font-size: 50px;"> Impacto da sazonalidade na ACF </span>


- Quando os dados possuem sazonalidade, as autocorrelações serão maiores para as defasagens sazonais (em múltiplos do período sazonal) do que para outras defasagens.


```{r, warning=FALSE}
# Carregar pacotes
library(ggplot2)
library(forecast)
library(patchwork)
library(dplyr)

# Criar série puramente sazonal
set.seed(123)
tempo <- 1:60  # 5 anos mensais
sazonal <- sin(2 * pi * tempo / 12)  # padrão senoidal com período 12
serie <- data.frame(Tempo = tempo, Valor = sazonal)

# Gráfico da série temporal
g1 <- ggplot(serie, aes(x = Tempo, y = Valor)) +
  geom_line(color = "blue") +
  labs(title = "Série puramente sazonal (período = 12)",
       x = "Tempo", y = "Valor") +
  theme_minimal()

# Gráfico da ACF
g2 <- ggAcf(serie$Valor, lag.max = 36) +
  labs(title = "ACF da série sazonal") +
  theme_minimal()

# Mostrar lado a lado
g1 | g2

```



## <span style="font-size: 50px;"> Processos Autoregressivos </span>


- Em um modelo de regressão múltipla, predizemos a variável de interesse usando uma combinação linear de preditores (covariáveis). 

- Em um modelo de "Auto-regressão", prevemos a variável de interesse usando uma combinação linear de valores passados da própria variável.

**Definição:** Um modelo autoregressivo de ordem $p$ pode ser escrito como:

$$
y_t= \alpha +\phi_1 y_{t-1}+\phi_2 y_{t-2}+\cdots+\phi_p y_{t-p}+w_t
$$

em que $w_t$ é um ruído branco Gaussiano com média zero e variância $\sigma^2_w$, $\phi_1, \ldots, \phi_p$ são constantes, $y_{t-1}, \ldots, y_{t-p}$ são os valores das séries defasadas no tempo e $\alpha = \mu( 1 - \phi_1 - \cdots - \phi_p )$.

## <span style="font-size: 50px;"> Forma usando o operador diferença </span>

É bastante comum escrever a equação anterior usando o operador diferença da seguinte forma:

$$
\left( 1 - \phi_1 B - \phi_2 B^2 - \cdots - \phi_p B^p   \right) y_t = w_t,  
$$

ou de forma mais compacta como

$$
\phi( B ) y_t = w_t,  
$$

em que $\phi(B) =\left( 1 - \phi_1 B - \phi_2 B^2 - \cdots - \phi_p B^p \right)$.

**OBS:** um modelo autorregressivo de ordem $p$ é denominado como $\operatorname{AR}(p)$.

## <span style="font-size: 50px;"> Comportamento de processos Autoregressivos </span>

Os modelos autoregressivos podem modelar vários comportamento de séries temporais. 

```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)

# Definir parâmetros AR
params <- c(0.1, 0.5, -0.5, 0.9, -0.9, 0.01)

# Simular as séries
set.seed(123)
series_list <- map2(params, 1:length(params), function(phi, i) {
  data.frame(
    Tempo = 1:200,
    Valor = arima.sim(list(order = c(1, 0, 0), ar = phi), n = 200),
    Série = paste0("AR(1), φ = ", phi)
  )
})

# Combinar em um único data frame
df_series <- bind_rows(series_list)

# Plotar com ggplot2
ggplot(df_series, aes(x = Tempo, y = Valor)) +
  geom_line(color = "steelblue") +
  facet_wrap(~ Série, ncol = 2) +
  labs(title = "Séries AR(1) com diferentes valores de φ",
       x = "Tempo", y = "Valor") +
  theme_minimal()
```



## <span style="font-size: 50px;"> Região de estabilidade </span>

</br>

Os modelos autorregressivos são restritos a dados estacionários, caso em que algumas restrições nos valores dos parâmetros são necessárias.

</br>

-   Para um modelo AR(1): $-1<\phi_1<1$.

-   Para um modelo AR(2): $-1 < \phi_2 < 1$, $\phi_1+\phi_2<1$ e $\phi_2-\phi_1 < 1$

</br>

Quando $p \geq 3$, as restrições são muito mais complicadas.

## <span style="font-size: 45px;"> Processo de Médias Móveis </span>

Uma alternativa aos processos autoregressivos, é o modelo Médias Móveis de ordem $q$ ( Moving Average - MA($q$) ). Seja $w_t$ um ruído branco gaussiano ( $w_t \sim RB( 0, \sigma^2_w )$ ), então definimos um processo de médias movéis de ordem $q$ como:

$$
y_t= w_t +\theta_1 w_{t-1}+\theta_2 w_{t-2}+\cdots+\theta_q w_{t-q}, 
$$

em que $q$ são os lags no processo MA e $\theta_1, \ldots, \theta_q$ são os parâmetros do modelo.
Usando o operador de médias móveis

$$
\theta(B) = 1 + \theta_1 B + \theta_2 B^2 + \cdots + \theta_q B^q
$$

Podemos escrever o processo MA($q$) da seguinte forma:

$$
y_t = \theta (B) w_t.
$$

## <span style="font-size: 40px;"> Processo Autoregressivo de médias móveis (ARMA) </span>

</br>

Uma série temporal $y_t$ é um processo ARMA($p, q$) se é estacionário e

$$
\small
y_t = \alpha +\phi_1 y_{t-1}+\cdots+\phi_p y_{t-p}+ w_t +\theta_1 w_{t-1}+\cdots+\theta_q w_{t-q},
$$

em que $\phi_p \neq 0$, $\theta_q \neq 0$ e $\sigma^2_w > 0$. Os parâmetros $p$ e $q$ são as ordens dos modelos autoregressivo e médias móveis, respectivamente.

Em particular, o modelo ARMA($p, q$) pode ser escrito de forma concisa como:

$$
\phi(B) y_t = \theta (B) w_t
$$

esse é um processo causal e invertível.

## <span style="font-size: 50px;"> Autocorrelação nos processos MA </span>


```{r, warning=FALSE, message=FALSE}
 # Simular MA(1)
set.seed(123)
t1 <- arima.sim(list(order = c(0,0,1), ma = 0.8), n = 200)
df1 <- data.frame(Tempo = 1:200, Valor = as.numeric(t1))

# Gráficos para MA(1)
g1 <- ggplot(df1, aes(x = Tempo, y = Valor)) +
  geom_line(color = "steelblue") +
  labs(title = "MA(1): θ = 0.8", x = "Tempo", y = "Valor") +
  theme_minimal()

g1_acf <- ggAcf(t1) +
  labs(title = "ACF - MA(1)") +
  theme_minimal()

g1_pacf <- ggPacf(t1) +
  labs(title = "PACF - MA(1)") +
  theme_minimal()

# Simular MA(2)
t2 <- arima.sim(list(order = c(0,0,2), ma = c(0.8, -0.5)), n = 200)
df2 <- data.frame(Tempo = 1:200, Valor = as.numeric(t2))

# Gráficos para MA(2)
g2 <- ggplot(df2, aes(x = Tempo, y = Valor)) +
  geom_line(color = "darkgreen") +
  labs(title = "MA(2): θ1 = 0.8, θ2 = -0.5", x = "Tempo", y = "Valor") +
  theme_minimal()

g2_acf <- ggAcf(t2) +
  labs(title = "ACF - MA(2)") +
  theme_minimal()

g2_pacf <- ggPacf(t2) +
  labs(title = "PACF - MA(2)") +
  theme_minimal()

# Organizar os gráficos em 2 linhas (série + ACF + PACF)
(g1 | g1_acf | g1_pacf) / (g2 | g2_acf | g2_pacf)


    ```



## <span style="font-size: 50px;"> Autocorrelação parcial nos processos AR </span>


```{r, warning=FALSE, message=FALSE}
 # Simular AR(1)
set.seed(123)
t1 <- arima.sim(list(order = c(1,0,0), ar = 0.8), n = 200)
df1 <- data.frame(Tempo = 1:200, Valor = as.numeric(t1))

# Gráficos para AR(1)
g1 <- ggplot(df1, aes(x = Tempo, y = Valor)) +
  geom_line(color = "steelblue") +
  labs(title = "AR(1): ϕ = 0.8", x = "Tempo", y = "Valor") +
  theme_minimal()

g1_acf <- ggAcf(t1) +
  labs(title = "ACF - AR(1)") +
  theme_minimal()

g1_pacf <- ggPacf(t1) +
  labs(title = "PACF - AR(1)") +
  theme_minimal()

# Simular AR(2)
t2 <- arima.sim(list(order = c(2,0,0), ar = c(0.8, -0.5)), n = 200)
df2 <- data.frame(Tempo = 1:200, Valor = as.numeric(t2))

# Gráficos para AR(2)
g2 <- ggplot(df2, aes(x = Tempo, y = Valor)) +
  geom_line(color = "darkgreen") +
  labs(title = "AR(2): ϕ1 = 0.8, ϕ2 = -0.5", x = "Tempo", y = "Valor") +
  theme_minimal()

g2_acf <- ggAcf(t2) +
  labs(title = "ACF - AR(2)") +
  theme_minimal()

g2_pacf <- ggPacf(t2) +
  labs(title = "PACF - AR(2)") +
  theme_minimal()

# Organizar os gráficos em 2 linhas (série + ACF + PACF)
(g1 | g1_acf | g1_pacf) / (g2 | g2_acf | g2_pacf)


```

## <span style="font-size: 50px;"> Definição da ordem do processo via ACF e PACF </span>

</br>

- A autocorrelação de um processo MA($q$) é igual a zero para os lags \> $q$

</br>

- A autocorrelação parcial de um processo AR($p$) é zero para lags \> $p$. 

</br>

- Portanto, os gráficos da ACF e PACF podem auxiliar a escolha das ordens dos modelos AR e MA. Entretanto, adicionalmente deve ser usado critérios de seleção de modelos para a escolha dos modelos.


